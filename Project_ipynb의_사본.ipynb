{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb의 사본",
      "provenance": [],
      "mount_file_id": "1ohMQP7BD5QopDQM0rvhnHFVOiSwtrnRx",
      "authorship_tag": "ABX9TyMq3Jk8WUwI/5YdOJcoUXjr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7943534325d4455e980c72f50ae74cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_937193b4518543e3a17d2d1bf878a5f5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b05039edf0664b179586b71744675f28",
              "IPY_MODEL_1269bf20a8804264b10800308072fe42"
            ]
          }
        },
        "937193b4518543e3a17d2d1bf878a5f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b05039edf0664b179586b71744675f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a3a61409db4b41e5b71e135d0a2aae53",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b62411d36ba46acbcc8d4fea6107eb1"
          }
        },
        "1269bf20a8804264b10800308072fe42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e03323938eb419aa9dd42bfa403006e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/10 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ab4265153cb4a6a9df86928b556e215"
          }
        },
        "a3a61409db4b41e5b71e135d0a2aae53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b62411d36ba46acbcc8d4fea6107eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e03323938eb419aa9dd42bfa403006e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ab4265153cb4a6a9df86928b556e215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjnam95/Test002/blob/master/Project_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYrueAnHPUXu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjZWBlI9PUF_",
        "outputId": "3513f0ed-0bf5-42c3-d286-794fea3210a4"
      },
      "source": [
        "# 필요한 모듈을 설치합니다\n",
        "!pip install mxnet-cu101\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece==0.1.85\n",
        "!pip install transformers\n",
        "!pip install torch #원래 ==1.3.1\n",
        "\n",
        "#SKT에서 공개한 KoBERT 모델을 불러옵니다 \n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet-cu101\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/4f/2e51ae21a0361db5363915f042f872a7d4ca456094a0b9e0f967bdcf7729/mxnet_cu101-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (356.7MB)\n",
            "\u001b[K     |████████████████████████████████| 356.7MB 48kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (1.19.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\n",
            "Installing collected packages: graphviz, mxnet-cu101\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu101-1.8.0.post0\n",
            "Collecting gluonnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/81/a238e47ccba0d7a61dcef4e0b4a7fd4473cb86bed3d84dd4fe28d45a0905/gluonnlp-0.10.0.tar.gz (344kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 14.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (20.9)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595698 sha256=f2592be1b562250c2cc1904262a391af29cc643d91c2e8999cb596f5906ab146\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/65/52/63032864a0f31a08b9a88569f803b5bafac8abd207fd7f7534\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n",
            "Collecting sentencepiece==0.1.85\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/e0/1264990c559fb945cfb6664742001608e1ed8359eeec6722830ae085062b/sentencepiece-0.1.85-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 13.0MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/92/6153f4912b84ee1ab53ab45663d23e7cf3704161cb5ef18b0c07e207cef2/transformers-4.7.0-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 14.4MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 36.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 36.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.7.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-a7ax4qly\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-a7ax4qly\n",
            "Building wheels for collected packages: kobert\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.1.2-cp37-none-any.whl size=12718 sha256=e40d462accead6df19bf8369d0896f1714d053888c0469e3a9a1c7531d165292\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yi4c499b/wheels/a2/b0/41/435ee4e918f91918be41529283c5ff86cd010f02e7525aecf3\n",
            "Successfully built kobert\n",
            "Installing collected packages: kobert\n",
            "Successfully installed kobert-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hONKEACO3uJ"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjFhsFESO8uI"
      },
      "source": [
        "# import\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from kobert.utils import get_tokenizer \n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model \n",
        "\n",
        "from transformers import AdamW \n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3aPTCnFQsw-"
      },
      "source": [
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6E_p77FYwye"
      },
      "source": [
        "#GPU 사용 시 cuda\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz9pYf-zO8xv",
        "outputId": "4834fc26-a84d-4c6a-8a56-197ddb4a56f0"
      },
      "source": [
        "# get model and vocab file\n",
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[██████████████████████████████████████████████████]\n",
            "[██████████████████████████████████████████████████]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3Q54BiCfZo_",
        "outputId": "b6eacac0-32f5-4c5f-cac2-55cf9202364b"
      },
      "source": [
        "#koBERT의 토크나이저를 사용합니다\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0ZdIvkZfZh2"
      },
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkgFl9eLO80X"
      },
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=7,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        output = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        pooler = output[1]\n",
        "        \n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZYy_rXzkqXD"
      },
      "source": [
        "model = torch.load('/content/drive/MyDrive/kobert_balance_re.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfpNnRdzO84Y"
      },
      "source": [
        "# model = BERTClassifier(bertmodel,  dr_rate=0.005).to(device)\n",
        "# model.load_state_dict(torch.load('/content/drive/MyDrive/kobert_balance.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQjHj0MfO86n"
      },
      "source": [
        "# # 위에서 설정한 tok, max_len, batch_size, device를 그대로 입력\n",
        "# # comment : 예측하고자 하는 텍스트 데이터 리스트\n",
        "# def getSentimentValue(comment, tok, max_len, batch_size, device):\n",
        "#   commnetslist = [] # 텍스트 데이터를 담을 리스트\n",
        "#   emo_list = [] # 감성 값을 담을 리스트\n",
        "#   for c in comment: # 모든 사용자 입력문장(사용자 감정 입력값)\n",
        "#     commnetslist.append( [c, 5] ) # [사용자 입력 문장, 임의의 양의 정수값] 설정\n",
        "    \n",
        "#   pdData = pd.DataFrame( commnetslist, columns = [['Sentence', 'Emotion']] )\n",
        "#   pdData = pdData.values\n",
        "#   test_set = BERTDataset(pdData, 0, 1, tok, max_len, True, False) \n",
        "#   test_input = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=5)\n",
        "  \n",
        "#   for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_input):\n",
        "#     token_ids = token_ids.long().to(device)\n",
        "#     segment_ids = segment_ids.long().to(device)\n",
        "#     valid_length= valid_length \n",
        "#     # 이때, out이 예측 결과 리스트\n",
        "#     out = model(token_ids, valid_length, segment_ids)\n",
        "\t\n",
        "#     # e는 2가지 실수 값으로 구성된 리스트\n",
        "#     # 0번 인덱스가 더 크면 부정, 긍정은 반대\n",
        "#     for e in out:\n",
        "#       if e[0]>e[1]: # 부정\n",
        "#         value = 0\n",
        "#       else: #긍정\n",
        "#         value = 1\n",
        "#       emo_list.append(value)\n",
        "\n",
        "#   return emo_list # 텍스트 데이터에 1대1 매칭되는 감성값 리스트 반환"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA3ETt7szuUQ"
      },
      "source": [
        "df_test = pd.read_excel('/content/test1.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLxNa6ssO88O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368,
          "referenced_widgets": [
            "7943534325d4455e980c72f50ae74cd6",
            "937193b4518543e3a17d2d1bf878a5f5",
            "b05039edf0664b179586b71744675f28",
            "1269bf20a8804264b10800308072fe42",
            "a3a61409db4b41e5b71e135d0a2aae53",
            "1b62411d36ba46acbcc8d4fea6107eb1",
            "8e03323938eb419aa9dd42bfa403006e",
            "0ab4265153cb4a6a9df86928b556e215"
          ]
        },
        "outputId": "cc111a28-be08-401f-b385-9539777d577e"
      },
      "source": [
        "# 해당 데이터에 대해 분류를 시작합니다\n",
        "model.eval()\n",
        "answer=[]\n",
        "train_acc = 0.0\n",
        "test_acc = 0.0\n",
        "for batch_id, (token_ids, valid_length, segment_ids) in enumerate(tqdm_notebook('test1.xlsx')):\n",
        "  token_ids = token_ids.long().to(device)\n",
        "  segment_ids = segment_ids.long().to(device)\n",
        "  valid_length= valid_length\n",
        "  out = model(token_ids, valid_length, segment_ids)\n",
        "  max_vals, max_indices = torch.max(out, 1)\n",
        "  answer.append(max_indices.cpu().clone().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7943534325d4455e980c72f50ae74cd6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-900f267d80ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test1.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0msegment_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbSS5HNmbM7E"
      },
      "source": [
        "emotion = ['Angry', 'Neutral', 'Happiness', 'Sadness', 'Fear', 'Surprise', 'Disgust']\n",
        "emotion_dict = {num:key for num,key in enumerate(emotion)}\n",
        "\n",
        "a_emotion = []\n",
        "for a_emotion_array in answer:\n",
        "  a_emotion += [emotion_dict[i] for i in a_emotion_array]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdRm0NbibOLM"
      },
      "source": [
        "answer_df['A_Emotion'] = a_emotion\n",
        "answer_df.to_excel('./result.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ASW1DlXO8-Y"
      },
      "source": [
        "# def data_perprocess(data) : \n",
        "#   raw = re.split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMwWWYe_O9AQ"
      },
      "source": [
        "# def data_preprocess(data):\n",
        "#     raw = re.split('[\\r\\n\\.\\?\\!]', data)\n",
        "#     #raw = data.replace('\\r\\n', ' ').replace('.', ' ').replace('\\?', ' ')\n",
        "#     text = []\n",
        "    \n",
        "#     for val in raw:\n",
        "#         if val == '':\n",
        "#             continue\n",
        "#         text.append([val, 0.0])\n",
        "    \n",
        "    \n",
        "#     print(text)\n",
        "#     return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D6UzGmUO9CP"
      },
      "source": [
        "# def predict(model, text):\n",
        "#     device = torch.device(\"cuda:0\")\n",
        "#     max_len = 64\n",
        "#     batch_size = 64\n",
        "#     warmup_ratio = 0.1\n",
        "#     num_epochs = 2\n",
        "#     max_grad_norm = 1\n",
        "#     log_interval = 200 \n",
        "#     learning_rate =  5e-5\n",
        "    \n",
        "#     tokenizer = get_tokenizer()\n",
        "#     bertmodel, vocab = get_pytorch_kobert_model()\n",
        "#     tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "#     data_test = BERTDataset(text, 0, 1, tok, max_len, True, False)\n",
        "#     test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=0)\n",
        "#     model.eval()\n",
        "    \n",
        "#     answer=[]\n",
        "#     for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "#         token_ids = token_ids.long().to(device)\n",
        "#         segment_ids = segment_ids.long().to(device)\n",
        "#         valid_length= valid_length\n",
        "#         label = label.long().to(device)\n",
        "#         out = model(token_ids, valid_length, segment_ids)\n",
        "#         max_vals, max_indices = torch.max(out, 1)\n",
        "#         answer.append(max_indices.cpu().clone().numpy())\n",
        "    \n",
        "#     result = F.softmax(out)\n",
        "    \n",
        "#     print(result)\n",
        "#     return result\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqptEW8O9EP"
      },
      "source": [
        "def calc_result(result):\n",
        "    Angry = 0.0\n",
        "    Neutral = 0.0\n",
        "    Happiness = 0.0\n",
        "    Sadness = 0.0\n",
        "    Fear = 0.0\n",
        "    Surprise = 0.0\n",
        "    Disgust = 0.0\n",
        "    result = result.detach().cpu().clone().numpy()\n",
        "    \n",
        "    for data in result:\n",
        "        Angry += data[0] \n",
        "        Neutral += data[1] \n",
        "        Happiness += data[2]\n",
        "        Sadness += data[3]\n",
        "        Fear += data[4]\n",
        "        Surprise += data[5]\n",
        "        Disgust += data[6]\n",
        "    \n",
        "    result = [Angry, Neutral, Happiness, Sadness, Fear, Surprise, Disgust]\n",
        "    \n",
        "    \n",
        "    results = normalize(result)\n",
        "    results = [0.1 if x == 0.0 else x for x in results]\n",
        "    results = {'Angry': results[0], 'Neutral': results[1], 'Happiness': results[2], 'Sadness': results[3], 'Sadness': results[4], 'Surprise': results[5], 'Disgust': results[6]}\n",
        "    \n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p45nQcK9O9GH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}